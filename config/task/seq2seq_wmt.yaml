project_name: "infill_wmt_seq"
data:
  train_data_src: "data/wmt14_en_de/train.en"
  train_data_trg: "data/wmt14_en_de/train.de"
  eval_data_src: "data/wmt14_en_de/valid.en"
  eval_data_trg: "data/wmt14_en_de/valid.de"
  test_data_src: "data/wmt14_en_de/test.en"
  test_data_trg: "data/wmt14_en_de/test.de"
  debug_data_src: "data/wmt14_en_de/debug.en"
  debug_data_trg: "data/wmt14_en_de/debug.de"
  cache_dir: "data/wmt14_en_de/cache"
  processor: "seq"
train:
  output_dir: "ckpt/wmt14_en_de/seq_n_infill"
  logging_dir: "./logs"
  do_train: True
  num_train_epochs: 1000
  per_device_train_batch_size: 2
  weight_decay: 0.01
  logging_strategy: "steps"
  logging_steps: 10
  save_strategy: "steps"
  save_steps: 5000
  save_total_limit: 5
  learning_rate: 0.0005
  report_to: "wandb"
eval:
  do_eval: True
  do_predict: True
  predict_with_generate: True
  per_device_eval_batch_size: 16
  load_best_model_at_end: True
  evaluation_strategy: "steps"  # Add this line
  eval_steps: 1000
  metric_for_best_model: "rouge1"
  greater_is_better: True
test:
  per_device_eval_batch_size: 32
  test_output_dir: "./results"
  write_result: True
  write_to_file: "./results/c_trained_infill/s2sft_wmt14_en_de_t5_sample_length_5.txt"
  best_model_path: "ckpt/wmt14_en_de/seq_n_infill/checkpoint-215000"